[32m[0929 10:51:27 @logger.py:90][0m Argv: /Users/zengcd/PycharmProjects/MLDL/base/recognized/hed.py
[32m[0929 10:51:27 @fs.py:101][0m [5m[31mWRN[0m Env var $TENSORPACK_DATASET not set, using /Users/zengcd/tensorpack_data for datasets.
[32m[0929 10:51:27 @fs.py:104][0m Created the directory /Users/zengcd/tensorpack_data.
[32m[0929 10:56:27 @fs.py:73][0m Succesfully downloaded BSR_bsds500.tgz. 70763455 bytes.
[32m[0929 10:56:32 @param.py:208][0m Use train_log/hed/hyper.txt to set hyperparam: 'learning_rate'.
[32m[0929 10:56:32 @concurrency.py:267][0m [5m[31mWRN[0m Command 'nvidia-smi -L' failed, return code=127
[32m[0929 10:56:32 @concurrency.py:268][0m [5m[31mWRN[0m /bin/sh: nvidia-smi: command not found

[32m[0929 10:56:32 @gpu.py:59][0m Loading local devices by TensorFlow ...
[32m[0929 10:56:32 @interface.py:31][0m Automatically applying QueueInput on the DataFlow.
[32m[0929 10:56:32 @input_source.py:222][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0929 10:56:32 @training.py:111][0m Building graph for training tower 0 ...
[32m[0929 10:56:32 @registry.py:90][0m 'conv1_1': [?, 3, ?, ?] --> [?, 64, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv1_2': [?, 64, ?, ?] --> [?, 64, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'branch1/convfc': [?, 64, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'pool1': [?, 64, ?, ?] --> [?, 64, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv2_1': [?, 64, ?, ?] --> [?, 128, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv2_2': [?, 128, ?, ?] --> [?, 128, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'branch2/convfc': [?, 128, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'branch2/upsample2': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'pool2': [?, 128, ?, ?] --> [?, 128, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv3_1': [?, 128, ?, ?] --> [?, 256, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv3_2': [?, 256, ?, ?] --> [?, 256, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'conv3_3': [?, 256, ?, ?] --> [?, 256, ?, ?]
[32m[0929 10:56:32 @registry.py:90][0m 'branch3/convfc': [?, 256, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch3/upsample4': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch3/upsample2': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'pool3': [?, 256, ?, ?] --> [?, 256, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv4_1': [?, 256, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv4_2': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv4_3': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch4/convfc': [?, 512, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch4/upsample8': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch4/upsample4': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch4/upsample2': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'pool4': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv5_1': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv5_2': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'conv5_3': [?, 512, ?, ?] --> [?, 512, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch5/convfc': [?, 512, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch5/upsample16': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch5/upsample8': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch5/upsample4': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'branch5/upsample2': [?, 1, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @registry.py:90][0m 'convfcweight': [?, 5, ?, ?] --> [?, 1, ?, ?]
[32m[0929 10:56:33 @regularize.py:97][0m regularize_cost() found 19 variables to regularize.
[32m[0929 10:56:33 @regularize.py:21][0m The following tensors will be regularized: conv1_1/W:0, conv1_2/W:0, branch1/convfc/W:0, conv2_1/W:0, conv2_2/W:0, branch2/convfc/W:0, conv3_1/W:0, conv3_2/W:0, conv3_3/W:0, branch3/convfc/W:0, conv4_1/W:0, conv4_2/W:0, conv4_3/W:0, branch4/convfc/W:0, conv5_1/W:0, conv5_2/W:0, conv5_3/W:0, branch5/convfc/W:0, convfcweight/W:0
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_1/W' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_1/b' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_2/W' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_2/b' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_3/W' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'conv5_3/b' is multipled by 5
[32m[0929 10:56:34 @gradproc.py:259][0m Gradient of 'convfcweight/W' is multipled by 0.1
[32m[0929 10:56:34 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname              shape               #elements
----------------  ----------------  -----------
conv1_1/W         [3, 3, 3, 64]            1728
conv1_1/b         [64]                       64
conv1_2/W         [3, 3, 64, 64]          36864
conv1_2/b         [64]                       64
branch1/convfc/W  [1, 1, 64, 1]              64
branch1/convfc/b  [1]                         1
conv2_1/W         [3, 3, 64, 128]         73728
conv2_1/b         [128]                     128
conv2_2/W         [3, 3, 128, 128]       147456
conv2_2/b         [128]                     128
branch2/convfc/W  [1, 1, 128, 1]            128
branch2/convfc/b  [1]                         1
conv3_1/W         [3, 3, 128, 256]       294912
conv3_1/b         [256]                     256
conv3_2/W         [3, 3, 256, 256]       589824
conv3_2/b         [256]                     256
conv3_3/W         [3, 3, 256, 256]       589824
conv3_3/b         [256]                     256
branch3/convfc/W  [1, 1, 256, 1]            256
branch3/convfc/b  [1]                         1
conv4_1/W         [3, 3, 256, 512]      1179648
conv4_1/b         [512]                     512
conv4_2/W         [3, 3, 512, 512]      2359296
conv4_2/b         [512]                     512
conv4_3/W         [3, 3, 512, 512]      2359296
conv4_3/b         [512]                     512
branch4/convfc/W  [1, 1, 512, 1]            512
branch4/convfc/b  [1]                         1
conv5_1/W         [3, 3, 512, 512]      2359296
conv5_1/b         [512]                     512
conv5_2/W         [3, 3, 512, 512]      2359296
conv5_2/b         [512]                     512
conv5_3/W         [3, 3, 512, 512]      2359296
conv5_3/b         [512]                     512
branch5/convfc/W  [1, 1, 512, 1]            512
branch5/convfc/b  [1]                         1
convfcweight/W    [1, 1, 5, 1]                5[36m
Number of trainable variables: 37
Number of parameters (elements): 14716170
Storage space needed for all trainable variables: 56.14MB[0m
[32m[0929 10:56:34 @base.py:209][0m Setup callbacks graph ...
[32m[0929 10:56:34 @argtools.py:146][0m [5m[31mWRN[0m Starting a process with 'fork' method is not safe and may consume unnecessary extra CPU memory. Use 'forkserver/spawn' method (available after Py3.4) instead if you run into any issues. See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
[32m[0929 10:56:34 @inference_runner.py:149][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0929 10:56:35 @summary.py:47][0m [MovingAverageSummary] 9 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0929 10:56:35 @summary.py:94][0m Summarizing collection 'summaries' of size 29.
[32m[0929 10:56:35 @base.py:230][0m Creating the session ...
[32m[0929 10:56:37 @base.py:236][0m Initializing the session ...
[32m[0929 10:56:37 @base.py:243][0m Graph Finalized.
[32m[0929 10:56:37 @concurrency.py:37][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0929 10:56:37 @inference_runner.py:96][0m [InferenceRunner] Will eval 100 iterations
[32m[0929 10:56:38 @base.py:275][0m Start Epoch 1 ...
[32m[0929 10:56:39 @parallel.py:97][0m [MultiProcessRunnerZMQ] Context terminated.
[32m[0929 10:56:39 @input_source.py:167][0m [EnqueueThread] DataFlow has terminated.
[32m[0929 10:56:39 @input_source.py:178][0m [EnqueueThread] Thread EnqueueThread QueueInput/input_queue Exited.
